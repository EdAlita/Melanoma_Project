{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, average_precision_score, f1_score, cohen_kappa_score, recall_score, log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier    \n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, Lars, ElasticNet, RidgeClassifier, BayesianRidge\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "\n",
    "time = strftime(\"%Y-%m-%d_%H-%M-%S\", gmtime())\n",
    "\n",
    "classifiers = [\n",
    "                RandomForestClassifier(criterion='entropy', max_depth=20, n_estimators=10, max_features=1),\n",
    "                KNeighborsClassifier(1),\n",
    "            ]\n",
    "\n",
    "# Define the threshold for binary classification\n",
    "threshold = 0.5\n",
    "\n",
    "# Define a custom scoring function\n",
    "def custom_score(y_true, y_pred, fn=accuracy_score):\n",
    "    # Apply the threshold to obtain binary predictions\n",
    "    y_pred_binary = np.where(y_pred >= threshold, 1, 0)\n",
    "\n",
    "    # Calculate and return the custom metric\n",
    "    # Replace this with your own custom metric calculation\n",
    "    return fn(y_true, y_pred_binary)\n",
    "\n",
    "\n",
    "\n",
    "def eval_classifiers(X, y, labels, **kwargs):\n",
    "\n",
    "    cv_scorers = {\n",
    "    'accuracy_score': make_scorer(accuracy_score),\n",
    "    # 'cross_entropy_loss': make_scorer(log_loss, labels=labels),\n",
    "    # 'average_precision_score' : make_scorer(average_precision_score, average='weighted', pos_label =0),\n",
    "    'cohen_kappa_score' : make_scorer(cohen_kappa_score, labels=labels),\n",
    "    'f1_score' : make_scorer(f1_score, average='weighted', labels=labels),\n",
    "    'recall_score' : make_scorer(recall_score, average='weighted', labels=labels),\n",
    "    # 'roc_auc_score': make_scorer(roc_auc_score, average='weighted', labels=labels, multi_class = 'ovr'),\n",
    "    # 'specificity_score' : make_scorer(recall_score, pos_label=0, average='binary', labels=labels),\n",
    "    }\n",
    "    # Define the list of scoring metrics\n",
    "    mean_res = pd.DataFrame()\n",
    "    std_res = pd.DataFrame()\n",
    "    \n",
    "    for i, clf in tqdm(enumerate(classifiers), desc=\"Classifiers are running....\"):\n",
    "        # ax = plt.subplot(len(classifiers) + 1, i)\n",
    "        clf_key = str(clf)\n",
    "        \n",
    "        \n",
    "        clf = Pipeline(steps=[('scaler',StandardScaler()),\n",
    "                            ('estimator',clf)])\n",
    "        \n",
    "        # Apply cross-validated model here.\n",
    "        cv = StratifiedKFold(n_splits=100, shuffle=True)  # Specify the number of desired folds\n",
    "        cv_scores = cross_validate(clf, X, y, cv=cv, scoring=cv_scorers, return_train_score=False, return_estimator=True, n_jobs=-1,verbose=2)  # Specify the list of scoring metrics\n",
    "        # print(cv_scores)\n",
    "        # print(np.array(cv_scores.values()))\n",
    "        estimators = cv_scores['estimator']\n",
    "\n",
    "        # Delete estimators\n",
    "        del cv_scores['estimator']\n",
    "        # Use sklearn metrics AUC.\n",
    "        for j, key in enumerate(cv_scores.keys()):\n",
    "            mean_res.loc[clf_key, key] = np.mean(cv_scores[key])\n",
    "            std_res.loc[clf_key, key] = np.std(cv_scores[key])\n",
    "\n",
    "    \n",
    "    return estimators, mean_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('../features/all/features_train_HSV_GLCM_shape_MC.csv')\n",
    "\n",
    "if len(data['label'].unique()) == 2:\n",
    "    category_mapping = {'nevus': 1, 'others': 0} # Should we switch?\n",
    "    labels = [0, 1]\n",
    "\n",
    "else:\n",
    "    data_exc = data[data['label'].isin(['mel', 'bcc', 'scc'])]\n",
    "    category_mapping = {\n",
    "                        'mel': 0, \n",
    "                        'bcc': 1, \n",
    "                        'scc': 2, \n",
    "                        }\n",
    "    labels = [0, 1, 2]\n",
    "    \n",
    "\n",
    "y_train =  data_exc['label'].astype('category').map(category_mapping)\n",
    "\n",
    "X = data_exc.iloc[:, 1:-1]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X)\n",
    "\n",
    "# PCA\n",
    "# pca = PCA(0.75)\n",
    "# pca.fit(X_train_)\n",
    "# X_train_ = pca.transform(X_train_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators, mean_res = eval_classifiers(X_train_, y_train, labels = labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('../features/all/features_val_HSV_GLCM_shape_MC.csv')\n",
    "\n",
    "val_data_exc = val_data[val_data['label'].isin(list(category_mapping.keys()))]\n",
    "\n",
    "y_val =  val_data_exc['label'].astype('category').map(category_mapping)\n",
    "\n",
    "X = val_data_exc.iloc[:, 1:-1]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y)\n",
    "\n",
    "# Standardization\n",
    "X_val_ = scaler.transform(X)\n",
    "# X_val_ = pca.transform(X_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"null accuracy:\", 1/3 *100 )   \n",
    "\n",
    "acc_scores = {'bcc': 0.0, 'mel': 0.0, 'scc': 0.0}\n",
    "chk_score = 0.0\n",
    "\n",
    "for estimator in tqdm(estimators):\n",
    "    y_pred = estimator.predict(X_val_) \n",
    "    for i in range(3):\n",
    "        lab = list(category_mapping.keys())[i]\n",
    "        y_test_slice = y[y == i]\n",
    "        y_pred_slice = y_pred[y == i]\n",
    "        # print(i, len(y_test_slice), len(y_pred_slice), np.unique(y_test_slice), np.unique(y_pred_slice))\n",
    "        acc_scores[lab] += accuracy_score(y_test_slice, y_pred_slice)\n",
    "    \n",
    "    chk_score += cohen_kappa_score(y, y_pred, labels=labels)        \n",
    "\n",
    "for k, v in acc_scores.items():\n",
    "\n",
    "    acc_scores[k] = v / len(estimators)\n",
    "\n",
    "    chk_score /= len(estimators)\n",
    "\n",
    "print(acc_scores, chk_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy_score</th>\n",
       "      <th>test_cohen_kappa_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier(criterion='entropy', max_depth=20, max_features=1,\\n                       n_estimators=10)</th>\n",
       "      <td>0.491538</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>0.522667</td>\n",
       "      <td>0.062969</td>\n",
       "      <td>0.486542</td>\n",
       "      <td>0.522667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier(n_neighbors=1)</th>\n",
       "      <td>0.136219</td>\n",
       "      <td>0.062024</td>\n",
       "      <td>0.530733</td>\n",
       "      <td>0.146475</td>\n",
       "      <td>0.524556</td>\n",
       "      <td>0.530733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    fit_time  score_time  \\\n",
       "RandomForestClassifier(criterion='entropy', max...  0.491538    0.013985   \n",
       "KNeighborsClassifier(n_neighbors=1)                 0.136219    0.062024   \n",
       "\n",
       "                                                    test_accuracy_score  \\\n",
       "RandomForestClassifier(criterion='entropy', max...             0.522667   \n",
       "KNeighborsClassifier(n_neighbors=1)                            0.530733   \n",
       "\n",
       "                                                    test_cohen_kappa_score  \\\n",
       "RandomForestClassifier(criterion='entropy', max...                0.062969   \n",
       "KNeighborsClassifier(n_neighbors=1)                               0.146475   \n",
       "\n",
       "                                                    test_f1_score  \\\n",
       "RandomForestClassifier(criterion='entropy', max...       0.486542   \n",
       "KNeighborsClassifier(n_neighbors=1)                      0.524556   \n",
       "\n",
       "                                                    test_recall_score  \n",
       "RandomForestClassifier(criterion='entropy', max...           0.522667  \n",
       "KNeighborsClassifier(n_neighbors=1)                          0.530733  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen-Kappa Score: 0.418972008139445\n"
     ]
    }
   ],
   "source": [
    "# Define the base classifiers\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = SVC(probability=True)\n",
    "\n",
    "# Create a Voting Classifier using majority voting\n",
    "voting_clf = VotingClassifier(estimators=[('dt', clf1), ('rf', clf2), ('svm', clf3)], voting='soft')\n",
    "\n",
    "# # Initialize a StratifiedKFold cross-validator\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Perform cross-validation with the Voting Classifier\n",
    "# predicted_labels = cross_val_predict(voting_clf, X_train_, y_train, cv=cv, method='predict')\n",
    "\n",
    "# # Calculate the accuracy across all cross-validation folds\n",
    "# accuracy = accuracy_score(y_train, predicted_labels)\n",
    "\n",
    "# print(\"Cross-validated Accuracy:\", accuracy)\n",
    "\n",
    "# cohen_kappa_ = cohen_kappa_score(y_train, predicted_labels, labels=labels)\n",
    "# print(\"Cohen-Kappa Score:\", cohen_kappa_)\n",
    "\n",
    "voting_clf.fit(X_train_, y_train)\n",
    "\n",
    "y_val_pred = voting_clf.predict(X_val_)\n",
    "\n",
    "cohen_kappa_ = cohen_kappa_score(y_val, y_val_pred, labels=labels)\n",
    "\n",
    "print(\"Cohen-Kappa Score:\", cohen_kappa_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 33.33333333333333\n",
      "{'bcc': 0.6686746987951807, 'mel': 0.7743362831858407, 'scc': 0.10638297872340426} 0.418972008139445\n"
     ]
    }
   ],
   "source": [
    "def show_score():\n",
    "    print(\"null accuracy:\", 1/3 *100 )   \n",
    "\n",
    "    acc_scores = {'bcc': 0.0, 'mel': 0.0, 'scc': 0.0}\n",
    "\n",
    "    for i in range(3):\n",
    "        lab = list(category_mapping.keys())[i]\n",
    "        y_test_slice = y_val[y_val == i]\n",
    "        y_pred_slice = y_val_pred[y_val == i]\n",
    "        # print(i, len(y_test_slice), len(y_pred_slice), np.unique(y_test_slice), np.unique(y_pred_slice))\n",
    "        acc_scores[lab] = accuracy_score(y_test_slice, y_pred_slice)\n",
    "\n",
    "        chk_score = cohen_kappa_score(y_val, y_val_pred, labels=labels)        \n",
    "\n",
    "\n",
    "    print(acc_scores, chk_score)\n",
    "\n",
    "show_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6244010320678216, 1: 0.8499749121926744, 2: 4.50531914893617}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train__, y_train_ = ros.fit_resample(X_train_, y_train)\n",
    "\n",
    "# Define the base classifiers\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = SVC(probability=True)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Create a dictionary mapping classes to their respective weights\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "print(class_weight_dict)\n",
    "\n",
    "# Create a Voting Classifier using majority voting\n",
    "voting_clf = VotingClassifier(estimators=[('dt', clf1), ('rf', clf2), ('svm', clf3)], voting='soft', weights=class_weights)\n",
    "\n",
    "# Fit & Predict\n",
    "voting_clf.fit(X_train__, y_train_) \n",
    "\n",
    "y_val_pred = voting_clf.predict(X_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 33.33333333333333\n",
      "{'bcc': 0.6987951807228916, 'mel': 0.799410029498525, 'scc': 0.13829787234042554} 0.4678973445669794\n"
     ]
    }
   ],
   "source": [
    "def show_score():\n",
    "    print(\"null accuracy:\", 1/3 *100 )   \n",
    "\n",
    "    acc_scores = {'bcc': 0.0, 'mel': 0.0, 'scc': 0.0}\n",
    "\n",
    "    for i in range(3):\n",
    "        lab = list(category_mapping.keys())[i]\n",
    "        y_test_slice = y_val[y_val == i]\n",
    "        y_pred_slice = y_val_pred[y_val == i]\n",
    "        # print(i, len(y_test_slice), len(y_pred_slice), np.unique(y_test_slice), np.unique(y_pred_slice))\n",
    "        acc_scores[lab] = accuracy_score(y_test_slice, y_pred_slice)\n",
    "\n",
    "        chk_score = cohen_kappa_score(y_val, y_val_pred, labels=labels)        \n",
    "\n",
    "\n",
    "    print(acc_scores, chk_score)\n",
    "\n",
    "show_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.7 + 0.8 + 0.14) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nevus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
