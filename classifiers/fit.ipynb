{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, average_precision_score, f1_score, cohen_kappa_score, recall_score, log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier    \n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, Lars, ElasticNet, RidgeClassifier, BayesianRidge\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "\n",
    "time = strftime(\"%Y-%m-%d_%H-%M-%S\", gmtime())\n",
    "\n",
    "classifiers = [\n",
    "                # RandomForestClassifier(criterion='entropy', max_depth=20, n_estimators=10, max_features=1),\n",
    "                # ExtraTreesClassifier(criterion='entropy', n_estimators=100, random_state=0),\n",
    "                # GaussianProcessClassifier(kernel=1.0 * RBF(1.0), random_state=0),\n",
    "                KNeighborsClassifier(1),\n",
    "            ]\n",
    "\n",
    "# Define the threshold for binary classification\n",
    "threshold = 0.5\n",
    "\n",
    "# Define a custom scoring function\n",
    "def custom_score(y_true, y_pred, fn=accuracy_score):\n",
    "    # Apply the threshold to obtain binary predictions\n",
    "    y_pred_binary = np.where(y_pred >= threshold, 1, 0)\n",
    "\n",
    "    # Calculate and return the custom metric\n",
    "    # Replace this with your own custom metric calculation\n",
    "    return fn(y_true, y_pred_binary)\n",
    "\n",
    "\n",
    "\n",
    "def eval_classifiers(X, y, labels, **kwargs):\n",
    "\n",
    "    cv_scorers = {\n",
    "    'accuracy_score': make_scorer(accuracy_score),\n",
    "    # 'cross_entropy_loss': make_scorer(log_loss, labels=labels),\n",
    "    # 'average_precision_score' : make_scorer(average_precision_score, average='weighted', pos_label =0),\n",
    "    'cohen_kappa_score' : make_scorer(cohen_kappa_score, labels=labels),\n",
    "    'f1_score' : make_scorer(f1_score, average='weighted', labels=labels),\n",
    "    'recall_score' : make_scorer(recall_score, average='weighted', labels=labels),\n",
    "    # 'roc_auc_score': make_scorer(roc_auc_score, average='weighted', labels=labels, multi_class = 'ovr'),\n",
    "    # 'specificity_score' : make_scorer(recall_score, pos_label=0, average='binary', labels=labels),\n",
    "    }\n",
    "    # Define the list of scoring metrics\n",
    "    mean_res = pd.DataFrame()\n",
    "    std_res = pd.DataFrame()\n",
    "    \n",
    "    for i, clf in tqdm(enumerate(classifiers), desc=\"Classifiers are running....\"):\n",
    "        # ax = plt.subplot(len(classifiers) + 1, i)\n",
    "        clf_key = str(clf)\n",
    "        \n",
    "        \n",
    "        clf = Pipeline(steps=[('scaler',StandardScaler()),\n",
    "                            ('pca', PCA(n_components=200)), \n",
    "                            ('estimator',clf)])\n",
    "        \n",
    "        # Apply cross-validated model here.\n",
    "        cv = StratifiedKFold(n_splits=100, shuffle=True)  # Specify the number of desired folds\n",
    "        cv_scores = cross_validate(clf, X, y, cv=cv, scoring=cv_scorers, return_train_score=False, return_estimator=True, n_jobs=-1,verbose=2)  # Specify the list of scoring metrics\n",
    "        # print(cv_scores)\n",
    "        # print(np.array(cv_scores.values()))\n",
    "        estimators = cv_scores['estimator']\n",
    "\n",
    "        # Delete estimators\n",
    "        del cv_scores['estimator']\n",
    "        # Use sklearn metrics AUC.\n",
    "        for j, key in enumerate(cv_scores.keys()):\n",
    "            mean_res.loc[clf_key, key] = np.mean(cv_scores[key])\n",
    "            std_res.loc[clf_key, key] = np.std(cv_scores[key])\n",
    "\n",
    "    \n",
    "    return estimators, mean_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifiers are running....: 0it [00:00, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "Classifiers are running....: 1it [01:22, 82.58s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('../features/all/features_train_HSV_GLCM_shape_MC.csv')\n",
    "\n",
    "if len(data['label'].unique()) == 2:\n",
    "    category_mapping = {'nevus': 1, 'others': 0} # Should we switch?\n",
    "    labels = [0, 1]\n",
    "\n",
    "else:\n",
    "    category_mapping = {'nev': 0, 'ack': 1, 'bcc': 2, 'bkl': 3, 'def': 4, 'mel':5, 'scc': 6, 'vac': 7}\n",
    "    labels = np.arange(8)\n",
    "    \n",
    "y =  data['label'].astype('category').map(category_mapping)\n",
    "\n",
    "X = data.iloc[:, 1:-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_ = scaler.transform(X_test)\n",
    "\n",
    "estimators, cv_metrics = eval_classifiers(X_train_, y_train, labels = labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 12.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:08<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nev': 67.24719585849873, 'ack': 20.96794871794874, 'bcc': 35.978260869565226, 'bkl': 28.411016949152526, 'def': 9.20930232558141, 'mel': 37.8955773955774, 'scc': 13.646017699115053, 'vac': 15.444444444444464}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# estimator = estimators[0]\n",
    "# print(estimator)\n",
    "print(\"null accuracy:\", 1/8 *100 )   \n",
    "acc_scores = {'nev': 0.0, 'ack': 0.0, 'bcc': 0., 'bkl': 0.0, 'def': 0.0, 'mel': 0.0, 'scc': 0.0, 'vac': 0.0}\n",
    "for estimator in tqdm(estimators):\n",
    "    y_pred = estimator.predict(X_test_) \n",
    "    for i in range(8):\n",
    "        lab = list(category_mapping.keys())[i]\n",
    "        y_test_slice = y_test[y_test == i]\n",
    "        y_pred_slice = y_pred[y_test == i]\n",
    "        # print(i, len(y_test_slice), len(y_pred_slice), np.unique(y_test_slice), np.unique(y_pred_slice))\n",
    "        acc_scores[lab] += accuracy_score(y_test_slice, y_pred_slice)*100\n",
    "\n",
    "for k, v in acc_scores.items():\n",
    "\n",
    "    acc_scores[k] = v / len(estimators)\n",
    "\n",
    "print(acc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nevus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
