{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, average_precision_score, f1_score, cohen_kappa_score, recall_score, log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier    \n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, Lars, ElasticNet, RidgeClassifier, BayesianRidge\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "\n",
    "time = strftime(\"%Y-%m-%d_%H-%M-%S\", gmtime())\n",
    "\n",
    "classifiers = [\n",
    "                RandomForestClassifier(criterion='entropy', max_depth=20, n_estimators=10, max_features=1),\n",
    "                KNeighborsClassifier(1),\n",
    "            ]\n",
    "\n",
    "# Define the threshold for binary classification\n",
    "threshold = 0.5\n",
    "\n",
    "# Define a custom scoring function\n",
    "def custom_score(y_true, y_pred, fn=accuracy_score):\n",
    "    # Apply the threshold to obtain binary predictions\n",
    "    y_pred_binary = np.where(y_pred >= threshold, 1, 0)\n",
    "\n",
    "    # Calculate and return the custom metric\n",
    "    # Replace this with your own custom metric calculation\n",
    "    return fn(y_true, y_pred_binary)\n",
    "\n",
    "\n",
    "\n",
    "def eval_classifiers(X, y, labels, **kwargs):\n",
    "\n",
    "    cv_scorers = {\n",
    "    'accuracy_score': make_scorer(accuracy_score),\n",
    "    # 'cross_entropy_loss': make_scorer(log_loss, labels=labels),\n",
    "    # 'average_precision_score' : make_scorer(average_precision_score, average='weighted', pos_label =0),\n",
    "    'cohen_kappa_score' : make_scorer(cohen_kappa_score, labels=labels),\n",
    "    'f1_score' : make_scorer(f1_score, average='weighted', labels=labels),\n",
    "    'recall_score' : make_scorer(recall_score, average='weighted', labels=labels),\n",
    "    # 'roc_auc_score': make_scorer(roc_auc_score, average='weighted', labels=labels, multi_class = 'ovr'),\n",
    "    # 'specificity_score' : make_scorer(recall_score, pos_label=0, average='binary', labels=labels),\n",
    "    }\n",
    "    # Define the list of scoring metrics\n",
    "    mean_res = pd.DataFrame()\n",
    "    std_res = pd.DataFrame()\n",
    "    \n",
    "    for i, clf in tqdm(enumerate(classifiers), desc=\"Classifiers are running....\"):\n",
    "        # ax = plt.subplot(len(classifiers) + 1, i)\n",
    "        clf_key = str(clf)\n",
    "        \n",
    "        \n",
    "        clf = Pipeline(steps=[('scaler',StandardScaler()),\n",
    "                            ('estimator',clf)])\n",
    "        \n",
    "        # Apply cross-validated model here.\n",
    "        cv = StratifiedKFold(n_splits=100, shuffle=True)  # Specify the number of desired folds\n",
    "        cv_scores = cross_validate(clf, X, y, cv=cv, scoring=cv_scorers, return_train_score=False, return_estimator=True, n_jobs=-1,verbose=2)  # Specify the list of scoring metrics\n",
    "        # print(cv_scores)\n",
    "        # print(np.array(cv_scores.values()))\n",
    "        estimators = cv_scores['estimator']\n",
    "\n",
    "        # Delete estimators\n",
    "        del cv_scores['estimator']\n",
    "        # Use sklearn metrics AUC.\n",
    "        for j, key in enumerate(cv_scores.keys()):\n",
    "            mean_res.loc[clf_key, key] = np.mean(cv_scores[key])\n",
    "            std_res.loc[clf_key, key] = np.std(cv_scores[key])\n",
    "\n",
    "    \n",
    "    return estimators, mean_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('../features/all/features_train_HSV_GLCM_shape_gloh_mc_final.csv')\n",
    "\n",
    "if len(data['label'].unique()) == 2:\n",
    "    category_mapping = {'nevus': 1, 'others': 0} # Should we switch?\n",
    "    labels = [0, 1]\n",
    "\n",
    "else:\n",
    "    data_exc = data[data['label'].isin(['mel', 'bcc', 'scc'])]\n",
    "    category_mapping = {\n",
    "                        'mel': 0, \n",
    "                        'bcc': 1, \n",
    "                        'scc': 2, \n",
    "                        }\n",
    "    labels = [0, 1, 2]\n",
    "    \n",
    "\n",
    "y_train =  data_exc['label'].astype('category').map(category_mapping)\n",
    "\n",
    "X = data_exc.iloc[:, 1:-1]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X)\n",
    "\n",
    "# PCA\n",
    "# pca = PCA(0.75)\n",
    "# pca.fit(X_train_)\n",
    "# X_train_ = pca.transform(X_train_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators, mean_res = eval_classifiers(X_train_, y_train, labels = labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('../features/all/features_val_HSV_GLCM_shape_gloh_mc_final.csv')\n",
    "\n",
    "val_data_exc = val_data[val_data['label'].isin(list(category_mapping.keys()))]\n",
    "\n",
    "y_val =  val_data_exc['label'].astype('category').map(category_mapping)\n",
    "\n",
    "X = val_data_exc.iloc[:, 1:-1]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y)\n",
    "\n",
    "# Standardization\n",
    "X_val_ = scaler.transform(X)\n",
    "# X_val_ = pca.transform(X_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"null accuracy:\", 1/3 *100 )   \n",
    "\n",
    "acc_scores = {'bcc': 0.0, 'mel': 0.0, 'scc': 0.0}\n",
    "chk_score = 0.0\n",
    "\n",
    "for estimator in tqdm(estimators):\n",
    "    y_pred = estimator.predict(X_val_) \n",
    "    for i in range(3):\n",
    "        lab = list(category_mapping.keys())[i]\n",
    "        y_test_slice = y[y == i]\n",
    "        y_pred_slice = y_pred[y == i]\n",
    "        # print(i, len(y_test_slice), len(y_pred_slice), np.unique(y_test_slice), np.unique(y_pred_slice))\n",
    "        acc_scores[lab] += accuracy_score(y_test_slice, y_pred_slice)\n",
    "    \n",
    "    chk_score += cohen_kappa_score(y, y_pred, labels=labels)        \n",
    "\n",
    "for k, v in acc_scores.items():\n",
    "\n",
    "    acc_scores[k] = v / len(estimators)\n",
    "\n",
    "    chk_score /= len(estimators)\n",
    "\n",
    "print(acc_scores, chk_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy_score</th>\n",
       "      <th>test_cohen_kappa_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier(criterion='entropy', max_depth=20, max_features=1,\\n                       n_estimators=10)</th>\n",
       "      <td>0.491538</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>0.522667</td>\n",
       "      <td>0.062969</td>\n",
       "      <td>0.486542</td>\n",
       "      <td>0.522667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier(n_neighbors=1)</th>\n",
       "      <td>0.136219</td>\n",
       "      <td>0.062024</td>\n",
       "      <td>0.530733</td>\n",
       "      <td>0.146475</td>\n",
       "      <td>0.524556</td>\n",
       "      <td>0.530733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    fit_time  score_time  \\\n",
       "RandomForestClassifier(criterion='entropy', max...  0.491538    0.013985   \n",
       "KNeighborsClassifier(n_neighbors=1)                 0.136219    0.062024   \n",
       "\n",
       "                                                    test_accuracy_score  \\\n",
       "RandomForestClassifier(criterion='entropy', max...             0.522667   \n",
       "KNeighborsClassifier(n_neighbors=1)                            0.530733   \n",
       "\n",
       "                                                    test_cohen_kappa_score  \\\n",
       "RandomForestClassifier(criterion='entropy', max...                0.062969   \n",
       "KNeighborsClassifier(n_neighbors=1)                               0.146475   \n",
       "\n",
       "                                                    test_f1_score  \\\n",
       "RandomForestClassifier(criterion='entropy', max...       0.486542   \n",
       "KNeighborsClassifier(n_neighbors=1)                      0.524556   \n",
       "\n",
       "                                                    test_recall_score  \n",
       "RandomForestClassifier(criterion='entropy', max...           0.522667  \n",
       "KNeighborsClassifier(n_neighbors=1)                          0.530733  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen-Kappa Score: 0.533370419207736\n"
     ]
    }
   ],
   "source": [
    "# Define the base classifiers\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = SVC(probability=True)\n",
    "\n",
    "# Create a Voting Classifier using majority voting\n",
    "voting_clf = VotingClassifier(estimators=[('dt', clf1), ('rf', clf2), ('svm', clf3)], voting='soft')\n",
    "\n",
    "# # Initialize a StratifiedKFold cross-validator\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Perform cross-validation with the Voting Classifier\n",
    "# predicted_labels = cross_val_predict(voting_clf, X_train_, y_train, cv=cv, method='predict')\n",
    "\n",
    "# # Calculate the accuracy across all cross-validation folds\n",
    "# accuracy = accuracy_score(y_train, predicted_labels)\n",
    "\n",
    "# print(\"Cross-validated Accuracy:\", accuracy)\n",
    "\n",
    "# cohen_kappa_ = cohen_kappa_score(y_train, predicted_labels, labels=labels)\n",
    "# print(\"Cohen-Kappa Score:\", cohen_kappa_)\n",
    "\n",
    "voting_clf.fit(X_train_, y_train)\n",
    "\n",
    "y_val_pred = voting_clf.predict(X_val_)\n",
    "\n",
    "cohen_kappa_ = cohen_kappa_score(y_val, y_val_pred, labels=labels)\n",
    "\n",
    "print(\"Cohen-Kappa Score:\", cohen_kappa_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 33.33333333333333\n",
      "{'bcc': 0.7369477911646586, 'mel': 0.8333333333333334, 'scc': 0.18085106382978725} 0.533370419207736\n"
     ]
    }
   ],
   "source": [
    "def show_score():\n",
    "    print(\"null accuracy:\", 1/3 *100 )   \n",
    "\n",
    "    acc_scores = {'bcc': 0.0, 'mel': 0.0, 'scc': 0.0}\n",
    "\n",
    "    for i in range(3):\n",
    "        lab = list(category_mapping.keys())[i]\n",
    "        y_test_slice = y_val[y_val == i]\n",
    "        y_pred_slice = y_val_pred[y_val == i]\n",
    "        # print(i, len(y_test_slice), len(y_pred_slice), np.unique(y_test_slice), np.unique(y_pred_slice))\n",
    "        acc_scores[lab] = accuracy_score(y_test_slice, y_pred_slice)\n",
    "\n",
    "        chk_score = cohen_kappa_score(y_val, y_val_pred, labels=labels)        \n",
    "\n",
    "\n",
    "    print(acc_scores, chk_score)\n",
    "\n",
    "show_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6244010320678216, 1: 0.8499749121926744, 2: 4.50531914893617}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train__, y_train_ = ros.fit_resample(X_train_, y_train)\n",
    "\n",
    "# Define the base classifiers\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = SVC(probability=True)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Create a dictionary mapping classes to their respective weights\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "print(class_weight_dict)\n",
    "\n",
    "# Create a Voting Classifier using majority voting\n",
    "voting_clf = VotingClassifier(estimators=[('dt', clf1), ('rf', clf2), ('svm', clf3)], voting='soft', weights=class_weights)\n",
    "\n",
    "# Fit & Predict\n",
    "voting_clf.fit(X_train__, y_train_) \n",
    "\n",
    "y_val_pred = voting_clf.predict(X_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 33.33333333333333\n",
      "{'bcc': 0.7228915662650602, 'mel': 0.7861356932153393, 'scc': 0.48936170212765956} 0.5504314198568636\n"
     ]
    }
   ],
   "source": [
    "show_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6606666666666667"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.713 + 0.79 + 0.479) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../features/all/features_train_HSV_GLCM_shape_gloh_mc_final.csv')\n",
    "\n",
    "if len(data['label'].unique()) == 2:\n",
    "    category_mapping = {'nevus': 1, 'others': 0} # Should we switch?\n",
    "    labels = [0, 1]\n",
    "\n",
    "else:\n",
    "    data_exc = data[data['label'].isin(['mel', 'bcc', 'scc'])]\n",
    "    category_mapping = {\n",
    "                        'mel': 0, \n",
    "                        'bcc': 1, \n",
    "                        'scc': 2, \n",
    "                        }\n",
    "    labels = [0, 1, 2]\n",
    "    \n",
    "\n",
    "y1 =  data_exc['label'].astype('category').map(category_mapping)\n",
    "\n",
    "X1  = data_exc.iloc[:, 1:-1]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y)\n",
    "\n",
    "data = pd.read_csv('../features/all/features_val_HSV_GLCM_shape_gloh_mc_final.csv')\n",
    "\n",
    "data_exc = data[data['label'].isin(list(category_mapping.keys()))]\n",
    "\n",
    "y2 =  data_exc['label'].astype('category').map(category_mapping)\n",
    "\n",
    "X2 = data_exc.iloc[:, 1:-1]\n",
    "\n",
    "X_train = pd.concat([X1, X2])\n",
    "y_train = pd.concat([y1, y2])\n",
    "\n",
    "# X_train = np.concatenate([X1, X2])\n",
    "# y_train = np.concatenate([y1, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6243979160522953, 1: 0.8499933092466212, 2: 4.5049645390070925}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../features/all/features_test_HSV_GLCM_shape_gloh_mc_final.csv')\n",
    "X_test = data.iloc[:, 1:-1]\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled, y_train = np.asarray(X_train_scaled), np.asarray(y_train)\n",
    "\n",
    "np.random.shuffle(np.asarray(X_train_scaled))\n",
    "np.random.shuffle(np.asarray(y_train))\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Define the base classifiers\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = SVC(probability=True)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train)\n",
    "\n",
    "# Create a dictionary mapping classes to their respective weights\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "print(class_weight_dict)\n",
    "\n",
    "# Create a Voting Classifier using majority voting\n",
    "voting_clf = VotingClassifier(estimators=[('dt', clf1), ('rf', clf2), ('svm', clf3)], voting='soft', weights=class_weights)\n",
    "\n",
    "# Fit & Predict\n",
    "voting_clf.fit(X_train_resampled, y_train_resampled) \n",
    "\n",
    "y_test_pred = voting_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3364, 2445,  531], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'../classifiers/results/binary_output_MC_2.csv'\n",
    "\n",
    "df = data.iloc[:, :1].copy()\n",
    "\n",
    "df.loc[:, 'preds'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save = df.sort_values('fname').reset_index().drop('index', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx00983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxx01561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxx00118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxx00466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxx01051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>xxx00998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>xxx01681</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>xxx00636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>xxx01964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>xxx00442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fname  preds\n",
       "0     xxx00983      0\n",
       "1     xxx01561      1\n",
       "2     xxx00118      0\n",
       "3     xxx00466      0\n",
       "4     xxx01051      0\n",
       "...        ...    ...\n",
       "2116  xxx00998      0\n",
       "2117  xxx01681      2\n",
       "2118  xxx00636      1\n",
       "2119  xxx01964      0\n",
       "2120  xxx00442      0\n",
       "\n",
       "[2121 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nevus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
